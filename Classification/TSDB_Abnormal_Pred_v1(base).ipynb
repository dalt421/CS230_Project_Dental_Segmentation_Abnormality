{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKcBcKv8f4Z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "345d5f6d-e438-451f-e6c8-2b9cf2413bce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/644.1 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m276.5/644.1 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m644.1/644.1 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m71.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.3/615.3 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m107.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m15.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tf-keras 2.17.0 requires tensorflow<2.18,>=2.17, but you have tensorflow 2.18.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "#Abnormality Prediction base\n",
        "!pip install -q --upgrade keras-hub\n",
        "!pip install -q --upgrade keras  # Upgrade to Keras 3."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
        "\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import losses\n",
        "from keras import ops\n",
        "from keras import optimizers\n",
        "#from keras.optimizers import schedules\n",
        "from keras import metrics\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "import keras_hub\n",
        "\n",
        "# Import tensorflow for [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) and its preprocessing functions\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds"
      ],
      "metadata": {
        "id": "P8YO_3GSgOwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_gallery(images, titles=None, num_cols=3, figsize=(6, 12)):\n",
        "    num_images = len(images)\n",
        "    print(num_images)\n",
        "    images = np.asarray(images) / 255.0\n",
        "    images = np.minimum(np.maximum(images, 0.0), 1.0)\n",
        "    num_rows = (num_images + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, squeeze=False)\n",
        "    axes = axes.flatten()  # Flatten in case the axes is a 2D array\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        if i < num_images:\n",
        "            # Plot the image\n",
        "            ax.imshow(images[i])\n",
        "            ax.axis(\"off\")  # Remove axis\n",
        "            if titles and len(titles) > i:\n",
        "                ax.set_title(titles[i], fontsize=12)\n",
        "        else:\n",
        "            # Turn off the axis for any empty subplot\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "1rDJMKrKg-1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOqrVrTZgZKo",
        "outputId": "c9816327-9713-4bbc-dbc8-0b5e4c6ebcc4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "DATASET_DIR_IMG = '/content/drive/MyDrive/CS230_Project/Dental_DB/Classify/Data/'\n",
        "BATCH_SIZE = 4\n",
        "IMAGE_SIZE = (224, 224)\n",
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "tfds.disable_progress_bar()\n",
        "train_ds = tf.keras.utils.image_dataset_from_directory(DATASET_DIR_IMG, validation_split=0.1, subset=\"training\", seed=42, image_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]),  batch_size=BATCH_SIZE)\n",
        "val_ds = tf.keras.utils.image_dataset_from_directory(DATASET_DIR_IMG, validation_split=0.1, subset=\"validation\", seed=42, image_size=(IMAGE_SIZE[0], IMAGE_SIZE[1]),  batch_size=BATCH_SIZE)\n",
        "class_names = train_ds.class_names\n",
        "print(class_names)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "raN_LBQFgmMb",
        "outputId": "fa862622-643e-4490-d42f-8e33d7313555"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1000 files belonging to 2 classes.\n",
            "Using 900 files for training.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Using 100 files for validation.\n",
            "['Abnormal', 'Normal']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = len(train_ds.class_names)\n",
        "print(num_classes)\n",
        "\n",
        "resizing = keras.layers.Resizing(\n",
        "    IMAGE_SIZE[0], IMAGE_SIZE[1], crop_to_aspect_ratio=True\n",
        ")\n",
        "\n",
        "def preprocess_inputs(image, label):\n",
        "    image = tf.cast(image, tf.float32) / 255.0\n",
        "    # Staticly resize images as we only iterate the dataset once.\n",
        "    return image, tf.one_hot(label, num_classes)\n",
        "\n",
        "train_ds = train_ds.map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\n",
        "val_ds = val_ds.map(preprocess_inputs, num_parallel_calls=AUTOTUNE)\n",
        "#train_ds = train_ds.batch(BATCH_SIZE)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QKrEN5b6mdAo",
        "outputId": "c5cdfaae-ba95-4fd1-87f9-4dedce499b75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "images = next(iter(train_ds.take(1)))[0]\n",
        "plot_image_gallery(images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 977
        },
        "id": "QjhEss53lCTI",
        "outputId": "02421059-2516-4d0d-96fd-41e02fd2eafd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 600x1200 with 33 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in train_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J77txBCmFIT0",
        "outputId": "85b7d303-f0f8-46d7-8e6f-c855b63506cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for image_batch, labels_batch in val_ds:\n",
        "  print(image_batch.shape)\n",
        "  print(labels_batch.shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-lI2K094LbeC",
        "outputId": "1b26ccfe-10b4-47a9-813b-10299451976c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(32, 224, 224, 3)\n",
            "(32, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "train_ds = train_ds.cache().shuffle(100).prefetch(buffer_size=AUTOTUNE)\n",
        "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
      ],
      "metadata": {
        "id": "6FV36vg9FNod"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SYWjFtt2FTeZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = keras_hub.models.ImageClassifier.from_preset(\n",
        "    \"resnet_18_imagenet\", num_classes=2\n",
        ")\n",
        "image_features = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
        "image_input = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), name='image')\n",
        "\n",
        "image_features = tf.keras.layers.Dense(256, activation=\"relu\")(image_features)\n",
        "image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "image_features = tf.keras.layers.Dense(128, activation=\"relu\")(image_features)\n",
        "image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "image_features = tf.keras.layers.Dense(64, activation=\"relu\")(image_features)\n",
        "image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "output = tf.keras.layers.Dense(1, activation='sigmoid', name = \"main_output\")(image_features)\n",
        "model = tf.keras.Model(inputs=image_input, outputs=output, name = \"Image_Encoder\")"
      ],
      "metadata": {
        "id": "I0wKjGK8lGe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 486
        },
        "outputId": "480ef902-8a91-48c4-c7a4-8ec59f41120d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/resnetv1/keras/resnet_18_imagenet/2/download/config.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 836/836 [00:00<00:00, 1.03MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/resnetv1/keras/resnet_18_imagenet/2/download/task.json...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3.58k/3.58k [00:00<00:00, 4.10MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/resnetv1/keras/resnet_18_imagenet/2/download/task.weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 44.8M/44.8M [00:01<00:00, 29.9MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/models/keras/resnetv1/keras/resnet_18_imagenet/2/download/model.weights.h5...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 42.8M/42.8M [00:01<00:00, 39.1MB/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <ResNetImageClassifier name=res_net_image_classifier, built=True> (of type <class 'keras_hub.src.models.resnet.resnet_image_classifier.ResNetImageClassifier'>)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-9e200f18a8ac>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m\"resnet_18_imagenet\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m )\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mimage_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGlobalAveragePooling2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mimage_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mIMAGE_SIZE\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'image'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m             \u001b[0;31m# `keras.config.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    123\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/layers/layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    806\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                 ):\n\u001b[0;32m--> 808\u001b[0;31m                     raise ValueError(\n\u001b[0m\u001b[1;32m    809\u001b[0m                         \u001b[0;34m\"Only input tensors may be passed as \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    810\u001b[0m                         \u001b[0;34m\"positional arguments. The following argument value \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Only input tensors may be passed as positional arguments. The following argument value should be passed as a keyword argument: <ResNetImageClassifier name=res_net_image_classifier, built=True> (of type <class 'keras_hub.src.models.resnet.resnet_image_classifier.ResNetImageClassifier'>)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_input = tf.keras.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), name='image')\n",
        "base_model = keras.applications.ResNet50(weights='imagenet', include_top=False)(image_input)\n",
        "image_features = tf.keras.layers.GlobalAveragePooling2D()(base_model)\n",
        "\n",
        "\n",
        "image_features = tf.keras.layers.Dense(256, activation=\"relu\")(image_features)\n",
        "image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "image_features = tf.keras.layers.Dense(128, activation=\"relu\")(image_features)\n",
        "image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "image_features = tf.keras.layers.Dense(64, activation=\"relu\")(image_features)\n",
        "image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "output = tf.keras.layers.Dense(2, activation='softmax', name = \"main_output\")(image_features)\n",
        "model = tf.keras.Model(inputs=image_input, outputs=output, name = \"Image_Encoder\")"
      ],
      "metadata": {
        "id": "ZUjcaYCuKxq0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c63d9c57-b5b3-4356-f1e3-cf630c9ea735"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def resnet18_with_regularization(input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3), num_classes=2, weight_decay=0.75):\n",
        "    inputs = tf.keras.Input(shape=input_shape)\n",
        "    base_model = keras.applications.ResNet50(\n",
        "        include_top=False,\n",
        "        weights=None,\n",
        "        input_tensor=inputs,\n",
        "        pooling=None\n",
        "    )\n",
        "\n",
        "    # Apply L2 regularization to each trainable layer in ResNet\n",
        "    for layer in base_model.layers:\n",
        "        if isinstance(layer, tf.keras.layers.Conv2D) or isinstance(layer, tf.keras.layers.Dense):\n",
        "            layer.kernel_regularizer = tf.keras.regularizers.l2(weight_decay)\n",
        "\n",
        "    # Add custom classification head\n",
        "    x = tf.keras.layers.GlobalAveragePooling2D()(base_model.output)\n",
        "    x = tf.keras.layers.Dense(256, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(weight_decay))(x)\n",
        "    outputs = tf.keras.layers.Dense(num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "    model = tf.keras.Model(inputs, outputs)\n",
        "    return model\n",
        "\n",
        "model = resnet18_with_regularization()"
      ],
      "metadata": {
        "id": "JdYbDxzjRaxk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    optimizer=keras.optimizers.Adam(learning_rate=0.0001),\n",
        "    metrics=[\"accuracy\", tf.keras.metrics.F1Score()],\n",
        ")"
      ],
      "metadata": {
        "id": "JD_kJRsEIPAh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(train_ds, epochs=20, validation_data=val_ds)"
      ],
      "metadata": {
        "id": "prKfyasRlytC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5372782b-abce-44eb-a454-f83056216249"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 52ms/step - accuracy: 0.5636 - f1_score: 0.4737 - loss: 259.7121 - val_accuracy: 0.3500 - val_f1_score: 0.2593 - val_loss: 95.8849\n",
            "Epoch 2/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.5852 - f1_score: 0.5100 - loss: 70.4585 - val_accuracy: 0.6500 - val_f1_score: 0.3939 - val_loss: 23.7077\n",
            "Epoch 3/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.6012 - f1_score: 0.5088 - loss: 17.1460 - val_accuracy: 0.6500 - val_f1_score: 0.3939 - val_loss: 5.6395\n",
            "Epoch 4/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6372 - f1_score: 0.5123 - loss: 4.1126 - val_accuracy: 0.6500 - val_f1_score: 0.3939 - val_loss: 1.8174\n",
            "Epoch 5/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6241 - f1_score: 0.4951 - loss: 1.3659 - val_accuracy: 0.6500 - val_f1_score: 0.3939 - val_loss: 0.9609\n",
            "Epoch 6/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6454 - f1_score: 0.5035 - loss: 0.7693 - val_accuracy: 0.6500 - val_f1_score: 0.3939 - val_loss: 0.7472\n",
            "Epoch 7/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.6752 - f1_score: 0.4917 - loss: 0.6383 - val_accuracy: 0.6300 - val_f1_score: 0.4324 - val_loss: 0.7161\n",
            "Epoch 8/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6881 - f1_score: 0.5909 - loss: 0.5935 - val_accuracy: 0.6400 - val_f1_score: 0.4152 - val_loss: 1.0242\n",
            "Epoch 9/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.6694 - f1_score: 0.5593 - loss: 0.6019 - val_accuracy: 0.5200 - val_f1_score: 0.5192 - val_loss: 0.6750\n",
            "Epoch 10/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 24ms/step - accuracy: 0.7104 - f1_score: 0.6347 - loss: 0.5536 - val_accuracy: 0.6500 - val_f1_score: 0.3939 - val_loss: 0.8203\n",
            "Epoch 11/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7305 - f1_score: 0.6508 - loss: 0.5276 - val_accuracy: 0.6400 - val_f1_score: 0.4918 - val_loss: 0.7917\n",
            "Epoch 12/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.7425 - f1_score: 0.7012 - loss: 0.5200 - val_accuracy: 0.5500 - val_f1_score: 0.4591 - val_loss: 0.9014\n",
            "Epoch 13/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.7917 - f1_score: 0.7696 - loss: 0.4870 - val_accuracy: 0.6300 - val_f1_score: 0.6161 - val_loss: 0.9991\n",
            "Epoch 14/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8233 - f1_score: 0.8078 - loss: 0.4057 - val_accuracy: 0.5700 - val_f1_score: 0.4608 - val_loss: 1.2170\n",
            "Epoch 15/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8468 - f1_score: 0.8316 - loss: 0.3590 - val_accuracy: 0.5800 - val_f1_score: 0.4792 - val_loss: 0.9975\n",
            "Epoch 16/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.8539 - f1_score: 0.8409 - loss: 0.3492 - val_accuracy: 0.6100 - val_f1_score: 0.4994 - val_loss: 1.4984\n",
            "Epoch 17/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9023 - f1_score: 0.8910 - loss: 0.2899 - val_accuracy: 0.5600 - val_f1_score: 0.4945 - val_loss: 1.1192\n",
            "Epoch 18/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9051 - f1_score: 0.8956 - loss: 0.2774 - val_accuracy: 0.6400 - val_f1_score: 0.5066 - val_loss: 1.3953\n",
            "Epoch 19/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 22ms/step - accuracy: 0.9247 - f1_score: 0.9153 - loss: 0.2119 - val_accuracy: 0.6300 - val_f1_score: 0.5552 - val_loss: 1.1740\n",
            "Epoch 20/20\n",
            "\u001b[1m225/225\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 23ms/step - accuracy: 0.9252 - f1_score: 0.9205 - loss: 0.2075 - val_accuracy: 0.6200 - val_f1_score: 0.5288 - val_loss: 1.3559\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Jg_Loy3yUVb9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training & validation loss values\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "APxuV7nPUxst"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model.summary())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "WUtJK9c2UtGv",
        "outputId": "5c1a5195-4608-47ec-e95c-fe5691cfc366"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mPreprocessor: \"res_net_image_classifier_preprocessor\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Preprocessor: \"res_net_image_classifier_preprocessor\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m                                  Config\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ res_net_image_converter (\u001b[38;5;33mResNetImageConverter\u001b[0m)                │                   Image size: (\u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m) │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                                  </span>┃<span style=\"font-weight: bold\">                                   Config </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ res_net_image_converter (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResNetImageConverter</span>)                │                   Image size: (<span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>) │\n",
              "└───────────────────────────────────────────────────────────────┴──────────────────────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"res_net_image_classifier\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"res_net_image_classifier\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                                 \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape                      \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m            Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12 (\u001b[38;5;33mInputLayer\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │                   \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ res_net_backbone (\u001b[38;5;33mResNetBackbone\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │          \u001b[38;5;34m11,186,112\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ pooler (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                        │                   \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ output_dropout (\u001b[38;5;33mDropout\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                        │                   \u001b[38;5;34m0\u001b[0m │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ predictions (\u001b[38;5;33mDense\u001b[0m)                           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)                          │               \u001b[38;5;34m1,026\u001b[0m │\n",
              "└───────────────────────────────────────────────┴────────────────────────────────────┴─────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                                  </span>┃<span style=\"font-weight: bold\"> Output Shape                       </span>┃<span style=\"font-weight: bold\">             Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ input_layer_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ res_net_backbone (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">ResNetBackbone</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │          <span style=\"color: #00af00; text-decoration-color: #00af00\">11,186,112</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ pooler (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                        │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ output_dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                        │                   <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├───────────────────────────────────────────────┼────────────────────────────────────┼─────────────────────┤\n",
              "│ predictions (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)                          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">1,026</span> │\n",
              "└───────────────────────────────────────────────┴────────────────────────────────────┴─────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m33,542,216\u001b[0m (127.95 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">33,542,216</span> (127.95 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,177,538\u001b[0m (42.64 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,177,538</span> (42.64 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m9,600\u001b[0m (37.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">9,600</span> (37.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m22,355,078\u001b[0m (85.28 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,355,078</span> (85.28 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    }
  ]
}