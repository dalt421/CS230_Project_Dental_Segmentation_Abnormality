{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JKcBcKv8f4Z5"
      },
      "outputs": [],
      "source": [
        "#Fusion Model with Text and Images for Abnormality Detection\n",
        "!pip install -q --upgrade keras-hub\n",
        "!pip install -q --upgrade keras  # Upgrade to Keras 3."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "#os.environ[\"KERAS_BACKEND\"] = \"jax\"  # @param [\"tensorflow\", \"jax\", \"torch\"]\n",
        "\n",
        "import json\n",
        "import math\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import keras\n",
        "from keras import losses\n",
        "from keras import ops\n",
        "from keras import optimizers\n",
        "#from keras.optimizers import schedules\n",
        "from keras import metrics\n",
        "from keras.applications.imagenet_utils import decode_predictions\n",
        "import keras_hub\n",
        "\n",
        "# Import tensorflow for [`tf.data`](https://www.tensorflow.org/api_docs/python/tf/data) and its preprocessing functions\n",
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from keras import layers\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow.keras.layers\n",
        "import tensorflow.keras.models\n",
        "import tensorflow.keras.preprocessing.text\n",
        "import tensorflow.keras.preprocessing.sequence\n",
        "from tensorflow.keras.layers import Input, Dense, Concatenate, GlobalAveragePooling2D, Embedding, LSTM\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "P8YO_3GSgOwN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_image_gallery(images, titles=None, num_cols=3, figsize=(6, 12)):\n",
        "    num_images = len(images)\n",
        "    print(num_images)\n",
        "    images = np.asarray(images) / 255.0\n",
        "    images = np.minimum(np.maximum(images, 0.0), 1.0)\n",
        "    num_rows = (num_images + num_cols - 1) // num_cols\n",
        "    fig, axes = plt.subplots(num_rows, num_cols, figsize=figsize, squeeze=False)\n",
        "    axes = axes.flatten()  # Flatten in case the axes is a 2D array\n",
        "\n",
        "    for i, ax in enumerate(axes):\n",
        "        if i < num_images:\n",
        "            # Plot the image\n",
        "            ax.imshow(images[i])\n",
        "            ax.axis(\"off\")  # Remove axis\n",
        "            if titles and len(titles) > i:\n",
        "                ax.set_title(titles[i], fontsize=12)\n",
        "        else:\n",
        "            # Turn off the axis for any empty subplot\n",
        "            ax.axis(\"off\")\n",
        "\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "metadata": {
        "id": "1rDJMKrKg-1m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOqrVrTZgZKo",
        "outputId": "a7003c2b-c4c3-47a8-ca56-156a78488dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def load_data(data_dir):\n",
        "  image_files = []\n",
        "  labels = []\n",
        "  for class_name in os.listdir(data_dir):\n",
        "    class_dir = os.path.join(data_dir, class_name)\n",
        "    print(class_name)\n",
        "    if os.path.isdir(class_dir):\n",
        "      for filename in os.listdir(class_dir):\n",
        "        file_path = os.path.join(class_dir, filename)\n",
        "        if filename.endswith(\".jpg\"):\n",
        "          image_files.append(file_path)\n",
        "          if(class_name == \"Abnormal\"):\n",
        "            labels.append(1)\n",
        "          else:\n",
        "            labels.append(0)\n",
        "          #labels.append(class_name)\n",
        "        #elif filename.endswith(\".txt\"):\n",
        "          #print(file_path)\n",
        "          #text_files.append(file_path)\n",
        "          #labels.append(class_name)\n",
        "\n",
        "  return image_files, labels\n",
        "\n",
        "def load_text(image_files):\n",
        "\n",
        "  text_files = []\n",
        "  for path in image_files:\n",
        "    #image = tf.io.read_file(image_path)\n",
        "    #img_count += 1\n",
        "    #image = tf.image.decode_jpeg(image, channels=3)\n",
        "    #image = tf.image.resize(image, [224, 224])  # Resize as needed\n",
        "    #image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
        "    text_path = path.replace(\".jpg\", \".txt\")\n",
        "    text_files.append(text_path)\n",
        "  #print(text_path)\n",
        "  return text_files\n",
        "\n",
        "def preprocess_image(image_path):\n",
        "  image = tf.io.read_file(image_path)\n",
        "  image = tf.image.decode_jpeg(image, channels=3)\n",
        "  image = tf.image.resize(image, [224, 224])  # Resize as needed\n",
        "  image = tf.cast(image, tf.float32) / 255.0  # Normalize\n",
        "  #text = text.to_tensor(default_value=\"UNK\")  # Handle empty sequences\n",
        "  return image\n",
        "\n",
        "def preprocess_text(text_path):\n",
        "  text = tf.io.read_file(text_path)\n",
        "  return text\n",
        "\n",
        "\n",
        "\n",
        "img_count = 0\n",
        "text_count = 0\n",
        "# Load and preprocess data\n",
        "image_files, labels = load_data(\"/content/drive/MyDrive/CS230_Project/Dental_DB/Classify/Data/\")\n",
        "text_files = load_text(image_files)\n",
        "\n",
        "\n",
        "image_dataset = tf.data.Dataset.from_tensor_slices(image_files)\n",
        "image_dataset = image_dataset.map(preprocess_image)\n",
        "\n",
        "text_dataset = tf.data.Dataset.from_tensor_slices(text_files)\n",
        "text_dataset = text_dataset.map(preprocess_text)\n",
        "text_processor = layers.TextVectorization(\n",
        "    max_tokens=20000,\n",
        "    output_sequence_length=100  # Pad sequences to a maximum length of 100\n",
        ")\n",
        "text_processor.adapt(text_dataset.map(lambda text: text))\n",
        "\n",
        "label_dataset = tf.data.Dataset.from_tensor_slices(labels)\n",
        "\n",
        "\n",
        "# Combine datasets\n",
        "dataset = tf.data.Dataset.zip((image_dataset, text_dataset), label_dataset)\n",
        "\n",
        "def preprocess_data(inputs, label):\n",
        "    image, text = inputs\n",
        "    processed_text = text_processor(text)\n",
        "    return (image, processed_text), label  # Return as ((image, text), label)\n",
        "\n",
        "def get_test_data(inputs, label):\n",
        "    image, text = inputs\n",
        "    #processed_text = text_processor(text)\n",
        "    return image, label  # Return as ((image, text), label)\n",
        "\n",
        "\n",
        "\n",
        "# Calculate the split sizes\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = int(0.1 * len(dataset))\n",
        "test_size = int(0.1 * len(dataset))\n",
        "\n",
        "# Shuffle the dataset\n",
        "dataset = dataset.shuffle(buffer_size=len(dataset))\n",
        "\n",
        "# Split the dataset\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size).take(val_size)\n",
        "test_dataset = dataset.skip(train_size + val_size).take(test_size)\n",
        "\n",
        "train_dataset = train_dataset.map(preprocess_data)\n",
        "val_dataset = val_dataset.map(preprocess_data)\n",
        "test_dataset = test_dataset.map(get_test_data)\n",
        "print(len(test_dataset))\n",
        "def format_data(inputs, label):\n",
        "    # Create a dictionary with two labels, one for each output layer\n",
        "    image, text = inputs\n",
        "    return (image, text), (label, label)\n",
        "\n",
        "# Apply the formatting function to your datasets\n",
        "train_dataset = train_dataset.map(format_data)\n",
        "val_dataset = val_dataset.map(format_data)\n",
        "#for sample in test_dataset.take(1):\n",
        "  #print(sample)\n",
        "  #print(sample[0].shape)\n",
        "#val_dataset = val_t_dataset.map(get_test_data)\n",
        "#test_dataset = full_dataset.skip(train_size + val_size)\n",
        "#test_dataset = test_dataset.map(preprocess_data)\n",
        "\n",
        "print(\"Number of images:\", img_count)\n",
        "print(\"Number of texts:\", text_count)\n",
        "# Apply the combine_data function to your datasets\n",
        "#train_dataset = train_dataset.map(lambda image, text, label: combine_data(image, text, label))\n",
        "#val_dataset = val_dataset.map(lambda image, text, label: combine_data(image, text, label))\n",
        "#val_dataset = test_dataset.skip(val_size)\n",
        "#test_dataset = test_dataset.take(test_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It_fVFv3hR-D",
        "outputId": "2b8c9a62-0a75-484d-ce47-3580f8d96671"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Abnormal\n",
            "Normal\n",
            "100\n",
            "Number of images: 0\n",
            "Number of texts: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = train_dataset.batch(32)  # Adjust batch size as needed\n",
        "val_dataset = val_dataset.batch(32)\n",
        "test_dataset = test_dataset.batch(32)"
      ],
      "metadata": {
        "id": "QNgSZuUICsde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def create_image_encoder():\n",
        " # #image_input = tf.keras.Input(shape=(224, 224, 3), name='image')\n",
        "  #base_model = ResNet50(weights='imagenet', include_top=False)(image_input)\n",
        " # image_features = tf.keras.layers.GlobalAveragePooling2D()(base_model)\n",
        " # return Model(inputs=image_input, outputs=image_features, name = \"Image_Encoder\")"
      ],
      "metadata": {
        "id": "4Me9gE73Rcz1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_image_encoder():\n",
        "  image_input = tf.keras.Input(shape=(224, 224, 3), name='image')\n",
        "  base_model = keras.applications.ResNet50(weights='imagenet', include_top=False)(image_input)\n",
        "  image_features = tf.keras.layers.GlobalAveragePooling2D()(base_model)\n",
        "\n",
        "\n",
        "  image_features = tf.keras.layers.Dense(256, activation=\"relu\")(image_features)\n",
        "  image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "  image_features = tf.keras.layers.Dense(128, activation=\"relu\")(image_features)\n",
        "  image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "  image_features = tf.keras.layers.Dense(64, activation=\"relu\")(image_features)\n",
        "  image_features = tf.keras.layers.Dropout(0.3)(image_features)\n",
        "  #output = tf.keras.layers.Dense(2, activation='softmax', name = \"main_output\")(image_features)\n",
        "  return Model(inputs=image_input, outputs=image_features, name = \"Image_Encoder\")"
      ],
      "metadata": {
        "id": "UOJ0ABgwkw5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def create_image_text_model():\n",
        "\n",
        "text_input = tf.keras.Input(shape=(None,), name='text')\n",
        "\n",
        "# Image processing layers\n",
        "image_encoder = create_image_encoder()\n",
        "image_input = image_encoder.input\n",
        "image_features = image_encoder.output\n",
        "\n",
        "# Text processing layers\n",
        "text_features = tf.keras.layers.Embedding(10000, 64)(text_input)\n",
        "text_features = tf.keras.layers.LSTM(64)(text_features)\n",
        "\n",
        "# Concatenate image and text features\n",
        "combined_features = tf.keras.layers.concatenate([image_features, text_features])\n",
        "combined_features = tf.keras.layers.Dense(64, activation='relu')(combined_features)\n",
        "compiled_features = tf.keras.layers.Dropout(0.3)(combined_features)\n",
        "# Output layer\n",
        "main_output = tf.keras.layers.Dense(1, activation='sigmoid', name = \"main_output\")(combined_features)\n",
        "\n",
        "aux_output = tf.keras.layers.Dense(1, activation='sigmoid', name='image_only_output')(image_features)\n",
        "\n",
        "# Create the model\n",
        "\n",
        "model = tf.keras.Model(inputs=[image_input, text_input], outputs=[main_output, aux_output])\n",
        "    #model._layers.append(image_encoder)  # Append model to _layers list.\n",
        "    #model._layers[-1]._name = \"Image_Encoder\" # Assign layer the desired name.\n",
        "    #return model\n",
        "\n",
        "#model = create_image_text_model()\n"
      ],
      "metadata": {
        "id": "MNcKAE_Rbodt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2143c2b2-66b0-42cb-9075-77236fe553dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss={ \"main_output\": \"binary_crossentropy\",\n",
        "        \"image_only_output\": \"binary_crossentropy\",\n",
        "    }, loss_weights={\"main_output\": 1.0, \"image_only_output\": 0.7}, metrics={'main_output': ['accuracy'], 'image_only_output': ['accuracy']}) # Provide a dictionary of metrics specifying metrics\n",
        "\n",
        "model.summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 673
        },
        "id": "GxQCMyTycuHH",
        "outputId": "818bfee1-be57-43a3-df97-0b3892e054d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"functional\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)             \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m       Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to          \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m3\u001b[0m)    │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2048\u001b[0m)     │     \u001b[38;5;34m23,587,712\u001b[0m │ image[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "│ (\u001b[38;5;33mGlobalAveragePooling2D\u001b[0m)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │        \u001b[38;5;34m524,544\u001b[0m │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │         \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text (\u001b[38;5;33mInputLayer\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m)           │              \u001b[38;5;34m0\u001b[0m │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │        \u001b[38;5;34m640,000\u001b[0m │ text[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │              \u001b[38;5;34m0\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │         \u001b[38;5;34m33,024\u001b[0m │ embedding[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (\u001b[38;5;33mConcatenate\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │              \u001b[38;5;34m0\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],       │\n",
              "│                           │                        │                │ lstm[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m8,256\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ main_output (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dense_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ image_only_output (\u001b[38;5;33mDense\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m65\u001b[0m │ dropout_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)              </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">        Param # </span>┃<span style=\"font-weight: bold\"> Connected to           </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
              "│ image (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)    │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │ image[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ global_average_pooling2d  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePooling2D</span>)  │                        │                │                        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">524,544</span> │ global_average_poolin… │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]            │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ text (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>)           │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │        <span style=\"color: #00af00; text-decoration-color: #00af00\">640,000</span> │ text[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">33,024</span> │ embedding[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ concatenate (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │              <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],       │\n",
              "│                           │                        │                │ lstm[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]             │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ main_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]          │\n",
              "├───────────────────────────┼────────────────────────┼────────────────┼────────────────────────┤\n",
              "│ image_only_output (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dropout_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]        │\n",
              "└───────────────────────────┴────────────────────────┴────────────────┴────────────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m24,834,818\u001b[0m (94.74 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,834,818</span> (94.74 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m24,781,698\u001b[0m (94.53 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">24,781,698</span> (94.53 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m53,120\u001b[0m (207.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">53,120</span> (207.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(train_dataset, epochs=20, validation_data=val_dataset)\n"
      ],
      "metadata": {
        "id": "R5L92IYYdG2g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(history.history['val_image_only_output_accuracy'])\n",
        "plt.plot(history.history['val_main_output_accuracy'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Image and Text', 'Image only'], loc='upper left')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gyGjz0Y5hVfR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_only_model = Model(inputs=image_input, outputs=aux_output)\n",
        "image_only_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
      ],
      "metadata": {
        "id": "4qdEgR25n1Df"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Get predictions\n",
        "y_pred_prob = image_only_model.predict(test_dataset)\n",
        "\n",
        "# Apply threshold\n",
        "y_pred = np.where(y_pred_prob > 0.98, 1, 0)  # Adjust 0.6 to your desired threshold\n",
        "\n",
        "# Calculate metrics\n",
        "\n",
        "def custom_accuracy(y_true, y_pred):\n",
        "    threshold = 0.99\n",
        "    y_pred = tf.where(y_pred > threshold, 1.0, 0.0)\n",
        "    return tf.keras.metrics.binary_accuracy(y_true, y_pred)\n",
        "image_only_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy', custom_accuracy])\n",
        "image_only_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "hx8KawTSnQXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image_only_model = Model(inputs=image_input, outputs=aux_output)\n",
        "image_only_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "image_only_model.evaluate(test_dataset)"
      ],
      "metadata": {
        "id": "hA7b7WbagM07"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}